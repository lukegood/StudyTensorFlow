{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epoch,w is 2.600000,loss is 36.000000\n",
      "After 1 epoch,w is 1.160000,loss is 12.959999\n",
      "After 2 epoch,w is 0.296000,loss is 4.665599\n",
      "After 3 epoch,w is -0.222400,loss is 1.679616\n",
      "After 4 epoch,w is -0.533440,loss is 0.604662\n",
      "After 5 epoch,w is -0.720064,loss is 0.217678\n",
      "After 6 epoch,w is -0.832038,loss is 0.078364\n",
      "After 7 epoch,w is -0.899223,loss is 0.028211\n",
      "After 8 epoch,w is -0.939534,loss is 0.010156\n",
      "After 9 epoch,w is -0.963720,loss is 0.003656\n",
      "After 10 epoch,w is -0.978232,loss is 0.001316\n",
      "After 11 epoch,w is -0.986939,loss is 0.000474\n",
      "After 12 epoch,w is -0.992164,loss is 0.000171\n",
      "After 13 epoch,w is -0.995298,loss is 0.000061\n",
      "After 14 epoch,w is -0.997179,loss is 0.000022\n",
      "After 15 epoch,w is -0.998307,loss is 0.000008\n",
      "After 16 epoch,w is -0.998984,loss is 0.000003\n",
      "After 17 epoch,w is -0.999391,loss is 0.000001\n",
      "After 18 epoch,w is -0.999634,loss is 0.000000\n",
      "After 19 epoch,w is -0.999781,loss is 0.000000\n",
      "After 20 epoch,w is -0.999868,loss is 0.000000\n",
      "After 21 epoch,w is -0.999921,loss is 0.000000\n",
      "After 22 epoch,w is -0.999953,loss is 0.000000\n",
      "After 23 epoch,w is -0.999972,loss is 0.000000\n",
      "After 24 epoch,w is -0.999983,loss is 0.000000\n",
      "After 25 epoch,w is -0.999990,loss is 0.000000\n",
      "After 26 epoch,w is -0.999994,loss is 0.000000\n",
      "After 27 epoch,w is -0.999996,loss is 0.000000\n",
      "After 28 epoch,w is -0.999998,loss is 0.000000\n",
      "After 29 epoch,w is -0.999999,loss is 0.000000\n",
      "After 30 epoch,w is -0.999999,loss is 0.000000\n",
      "After 31 epoch,w is -1.000000,loss is 0.000000\n",
      "After 32 epoch,w is -1.000000,loss is 0.000000\n",
      "After 33 epoch,w is -1.000000,loss is 0.000000\n",
      "After 34 epoch,w is -1.000000,loss is 0.000000\n",
      "After 35 epoch,w is -1.000000,loss is 0.000000\n",
      "After 36 epoch,w is -1.000000,loss is 0.000000\n",
      "After 37 epoch,w is -1.000000,loss is 0.000000\n",
      "After 38 epoch,w is -1.000000,loss is 0.000000\n",
      "After 39 epoch,w is -1.000000,loss is 0.000000\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.constant(5, dtype=tf.float32))\n",
    "lr = 0.2\n",
    "epoch = 40\n",
    "\n",
    "for epoch in range(epoch):  # for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环40次迭代。\n",
    "    with tf.GradientTape() as tape:  # with结构到grads框起了梯度的计算过程。\n",
    "        loss = tf.square(w + 1)\n",
    "    grads = tape.gradient(loss, w)  # .gradient函数告知谁对谁求导\n",
    "\n",
    "    w.assign_sub(lr * grads)  # .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads\n",
    "    print(\"After %s epoch,w is %f,loss is %f\" % (epoch, w.numpy(), loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
